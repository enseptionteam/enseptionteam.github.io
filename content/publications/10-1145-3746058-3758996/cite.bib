@inproceedings{10.1145/3746058.3758996,
 abstract = {This study presents a novel approach to improving musical haptic wearables by applying deep learning models for music source separation and pitch estimation. The system consists of a haptic vest and a pair of haptic gloves, designed to spatially convey musical elements throughout the body. By isolating instruments from an audio file and recognizing their pitches, our system provides intuitive haptic feedback that discretely represents each instrumentâ€™s performance. Specifically, we map the piano to the gloves, the bass to the back of the vest, and the drums to the front of the vest. Then, we conducted a comparative study with a conventional audio-to-haptic method. The results showed that users experienced improved clarity, intuitiveness, and comprehension, indicating enhanced understanding of musical structure.},
 address = {New York, NY, USA},
 articleno = {41},
 author = {Shin, Sungyong and Yi, HyeonBeom and Seo, Junsuk and Jeong, Chi Yoon and Lee, Chang Hee and Lee, Woohun and Nam, Juhan},
 booktitle = {Adjunct Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
 doi = {10.1145/3746058.3758996},
 isbn = {9798400720369},
 keywords = {musical haptics, wearable, audio to haptic},
 location = {},
 numpages = {3},
 publisher = {Association for Computing Machinery},
 series = {UIST Adjunct '25},
 title = {Haptic Music Feedback through Audio Decomposition},
 url = {https://doi.org/10.1145/3746058.3758996},
 year = {2025}
}
